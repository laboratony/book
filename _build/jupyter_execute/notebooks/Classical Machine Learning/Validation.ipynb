{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b6d638",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0361a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a35de",
   "metadata": {},
   "source": [
    "## Train-validation-test sets\n",
    "\n",
    "ที่ผ่านมา เราได้เรียนวิธีการแบ่ง dataset ออกเป็น training set กับ test set แต่ในความเป็นจริงเราไม่ทำแบบนั้น\n",
    "\n",
    "ขณะที่เรากำลังสร้าง model เราต้องทำการตัดสินใจหลายอย่าง เช่น เลือกชนิดของ model กำหนดค่าของ hyperparameter และ/หรือ เลือก feature ที่จะใช้หรือเอาออก เราไม่ควรใช้ test set ในการทดสอบ (validation) model แต่ละแบบ เพราะจะทำให้ model เรียนรู้ข้อมูลใน test set ทั้ง ๆ ที่กำลังอยู่ในกระบวนการ training เราควรแบ่งข้อมูลจาก training set ส่วนหนึ่งมาเป็น validation set แล้วใช้มันในการทดสอบ model แทน\n",
    "\n",
    "เราสามารถทำ validation ได้โดยใช้ validation set ที่แบ่งออกมาจาก training set แล้ว หรือทำ <b>cross-validation</b> ก็ได้\n",
    "\n",
    "<img src=\"../images/validation.png\" width=\"400\" /><br />\n",
    "\n",
    "## Cross validation\n",
    "\n",
    "K-fold cross-validation เป็นการแบ่ง training set ออกเป็น K ชุด เลือกใช้ข้อมูล 1 ชุดเป็น validation set และใช้ข้อมูลที่เหลือในการเทรน การเลือก training set และ validation set ที่ต่างกันจะได้ sub-model ที่ต่างกัน เอา performance ที่ประเมินได้จากแต่ละ sub-model มาเฉลี่ย ได้สิ่งที่เรียกว่า cross-validated score ของ model นั้น\n",
    "- หากใช้ K มาก จะทำให้การประเมิน performance มีความน่าเชื่อถือ แต่ก็ทำให้ computational cost สูงตามไปด้วย\n",
    "- K = 5-10 กำลังดี\n",
    "- ไม่ต้องเอา model ไป train (`.fit`) ก่อน\n",
    "- ใช้ `sklearn.model_selection.cross_validate` หรือ `sklearn.model_selection.cross_val_score` (หากต้องการแค่ score)\n",
    "\n",
    "4-fold cross-validation มีลักษณะดังภาพด้านล่าง\n",
    "\n",
    "<img src=\"../images/4_fold_cross_validation.png\" width=\"300\" /><br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d4e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data pre-processing - we need only numerical features to perform linear regression\n",
    "\n",
    "# Import data and drop duplicate\n",
    "data = pd.read_csv(\"../data/India_air_quality.csv\").drop_duplicates()\n",
    "# Separate features (X) and target (y)\n",
    "X, y = data.drop(columns=\"rspm\"), data['rspm']\n",
    "# Drop row containing non-sense values\n",
    "X = X.drop(X[(X['no2'] < 0) | (X['rainfall'] < 0)].index)\n",
    "y = y[X.index]\n",
    "# Drop features with missing values >30%\n",
    "X = X.drop(columns=[\"stn_code\", \"spm\", \"pm2_5\"])\n",
    "# Replace missing values in numerical columns with their means\n",
    "num_cols = X.select_dtypes(include=np.number).columns\n",
    "X[num_cols] = SimpleImputer(strategy=\"mean\").fit_transform(X[num_cols])\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "# We need only numerical features to perform linear regression\n",
    "X_train, X_test = X_train[[\"so2\", \"no2\", \"rainfall\"]], X_test[[\"so2\", \"no2\", \"rainfall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a68f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02202177, 0.02102017, 0.02130938, 0.02016401, 0.02006793]),\n",
       " 'score_time': array([0.00358176, 0.00331831, 0.00328827, 0.00324726, 0.00303531]),\n",
       " 'test_score': array([0.12877116, 0.11314677, 0.1259242 , 0.1296588 , 0.13311436])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-Fold cross-validation\n",
    "cv_results = cross_validate(LinearRegression(), X_train, y_train, cv=5)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1cd4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12877116, 0.11314677, 0.1259242 , 0.1296588 , 0.13311436])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-Fold cross-validation (only see scores)\n",
    "cv_scores = cross_val_score(LinearRegression(), X_train, y_train, cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eacf1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1261230571914333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the mean score\n",
    "cv_scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}